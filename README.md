# Sistema de Preven√ß√£o de Fraudes em Pix  em Tempo Real  


<img width="1080" height="670" alt="CienciaDadosPix" src="https://github.com/user-attachments/assets/f3ae5290-64d6-4e21-909e-152e4092b308" />



---

**Vis√£o Geral**

Este projeto implementa um sistema de detec√ß√£o de fraudes em transa√ß√µes Pix em tempo real, utilizando pipelines de ci√™ncia de dados, modelos de machine learning e boas pr√°ticas de engenharia de software.

O objetivo √© prevenir perdas financeiras e melhorar a experi√™ncia do cliente, oferecendo decis√µes r√°pidas com baixa lat√™ncia, mantendo alta precis√£o e reprodutibilidade.

---

**Motiva√ß√£o**

Criei este projeto para aplicar conhecimento em ci√™ncia de dados, engenharia de dados e machine learning em um problema real de fintechs e bancos digitais: fraudes em pagamentos instant√¢neos.

Minha inten√ß√£o foi:

‚Ä¢ Simular cen√°rios de transa√ß√µes reais, incluindo padr√µes suspeitos;

‚Ä¢ Construir pipelines escal√°veis e audit√°veis;

‚Ä¢ Aplicar modelos interpret√°veis (log√≠stica) e de alto desempenho (XGBoost/LightGBM);

‚Ä¢ Garantir governan√ßa de dados, qualidade de c√≥digo e m√©tricas de neg√≥cio.


---

**Problema que Resolve**

Fraudes em Pix podem gerar perdas milion√°rias e prejudicar a confian√ßa do cliente. O desafio √©:

‚Ä¢ Detectar fraudes em tempo real;

‚Ä¢ Minimizar falsos positivos que impactam a experi√™ncia do usu√°rio;

‚Ä¢ Otimizar custo financeiro agregado, considerando custo de fraude e opera√ß√£o;

‚Ä¢ Manter alta performance e monitoramento cont√≠nuo.


---




üõ†Ô∏è **Decis√µes T√©cnicas & Stack Estrat√©gica**

As escolhas abaixo visam equilibrar performance computacional, manutenibilidade de c√≥digo e valor de neg√≥cio:

| Componente | Escolha | Motiva√ß√£o |
|---|---|---|
| Linguagem | Python 3.12 | Vers√£o est√°vel com melhorias de performance e tipagem. |
| Processamento | Polars & PyArrow | Manipula√ß√£o de grandes volumes de dados com performance superior ao Pandas. |
| Modelagem | XGBoost & LogReg | Compara√ß√£o entre um modelo de alta performance e um baseline interpret√°vel. |
| Qualidade | Ruff, Mypy & Black | Garantia de c√≥digo limpo, tipagem est√°tica e padroniza√ß√£o autom√°tica. |
| Automa√ß√£o | Makefile & Poetry | Padroniza√ß√£o de comandos e gest√£o rigorosa de depend√™ncias. |
| CI/CD | GitHub Actions | Execu√ß√£o autom√°tica de testes e linters a cada novo commit. |
| Arquitetura | Pipelines Modulares | Separa√ß√£o clara entre Ingest√£o, Feature Engineering e Modelagem. |




---


**Trade-offs:**

‚Ä¢ Optei por Polars para performance em janelas temporais, embora Pandas seja mais comum;

‚Ä¢ Mantive regress√£o log√≠stica para interpretabilidade antes de aplicar modelos complexos;

‚Ä¢ Scripts detalhados foram priorizados em modularidade, mesmo aumentando a quantidade de arquivos.


---

**Tecnologias Utilizadas**

‚Ä¢ Ci√™ncia de Dados: Pandas, Polars, NumPy, PyArrow, Scikit-learn, XGBoost, LightGBM, Matplotlib, Seaborn

‚Ä¢ Qualidade: Black, Ruff, Isort, Mypy, Pytest

‚Ä¢ DevOps/Infra: Git, GitHub Actions, Poetry, pre-commit, Makefile

‚Ä¢ Ambiente: Python 3.12, JupyterLab/Notebook

---

**Como Executar**

**Pr√©-requisitos*"

‚Ä¢ CPU 4+ n√∫cleos, 16GB RAM, SSD recomendado

‚Ä¢ Python 3.12, Poetry 1.7+, Git, Make

‚Ä¢ JupyterLab para notebooks

**Passos**

**1. Clone o reposit√≥rio**

   ```
   git clone https://github.com/Santosdevbjj/prevencaoFraudesPix.git
cd prevencaoFraudesPix
```


**2.Instale depend√™ncias e pre-commit**

```
poetry install
poetry run pre-commit install
```


**3. Qualidade do c√≥digo**

```
poetry run black src tests
poetry run ruff check src tests --fix
poetry run isort src tests
poetry run mypy src
```

**4. Execu√ß√£o de pipelines**

```
poetry run python src/pipelines/build_dataset.py
poetry run python src/pipelines/trainandeval.py
poetry run python src/modeling/inference.py --input data/processed/realtimebatch.parquet --output models/reports/inferenceoutput.parquet
```

**5. Notebooks**

```
poetry run jupyter lab
# 01_eda.ipynb, 02featureinspection.ipynb, 03thresholdanalysis.ipynb
```

---

**Principais Aprendizados**

‚Ä¢ Import√¢ncia de separar regras de neg√≥cio, pipelines e modelos;

‚Ä¢ Uso de Polars e PyArrow aumentou performance em janelas temporais;

‚Ä¢ Gerenciamento de thresholds din√¢micos e m√©tricas de custo foi essencial para decis√µes financeiras;

‚Ä¢ Pipelines modularizadas e CI/CD reduzem risco operacional e facilitam manuten√ß√£o;

‚Ä¢ Experi√™ncia pr√°tica em detec√ß√£o de fraude real-time, m√©tricas de lat√™ncia e trade-offs de precis√£o/recall.

---


**Pr√≥ximos Passos**

‚Ä¢ Integra√ß√£o com sistemas de risco e device intelligence;

‚Ä¢ Automatizar re-treino baseado em drift de dados;

‚Ä¢ Expandir cobertura de testes e refatorar pipelines para microservices;

‚Ä¢ Explorar novos modelos interpret√°veis para auditoria regulat√≥ria.


---

**Impacto de Neg√≥cio**

‚Ä¢ Redu√ß√£o de perdas por fraude: detec√ß√£o em tempo real com ROC-AUC e PR-AUC superiores ao baseline;

‚Ä¢ Lat√™ncia m√©dia: <50 ms por transa√ß√£o, mantendo UX;

‚Ä¢ Custo otimizado: minimiza√ß√£o de custo total = custofraude √ó FN + custooperacional √ó FP;

‚Ä¢ Governan√ßa e auditabilidade: versionamento de modelos, artefatos e relat√≥rios.




---
---


**Passo a passo para criar e executar o projeto**

**Prepara√ß√£o do ambiente**

- **Hardware recomendado:**
  - CPU de m√∫ltiplos n√∫cleos (4+), 16 GB RAM para treinos confort√°veis.
  - 10‚Äì20 GB de disco para artefatos e datasets intermedi√°rios.
- **Software:**
  - Python 3.12.
  - Poetry 1.7+ para gerenciar depend√™ncias e ambientes.
  - Git e GitHub para versionamento e CI.
  - Make (GNU Make) para comandos padronizados.
  - JupyterLab/Notebook para explora√ß√£o.


---

**Instala√ß√£o**

**1. Instale Python 3.12 e pip.**
**2. Instale Poetry:**
   - Linux/macOS: curl -sSL https://install.python-poetry.org | python3 -
   - Windows: via installer oficial do Poetry.
**3. Clone o reposit√≥rio:**
   - git clone https://github.com/Santosdevbjj/prevencaoFraudesPix.git
   - cd prevencaoFraudesPix
**4. Crie e ative o ambiente:**
   - poetry install (ou poetry install --no-root se n√£o for empacotar o projeto)
**5. Instale pre-commit e ative hooks:**
   - poetry run pre-commit install


---

**Execu√ß√£o de qualidade local**

- **Formata√ß√£o e lint:**
  - poetry run black src tests
  - poetry run ruff check src tests --fix
  - poetry run isort src tests
- **Tipos:**
  - poetry run mypy src

**Execu√ß√£o de pipelines**

- Construir dataset:
  - poetry run python src/pipelines/build_dataset.py
- Treinar e avaliar:
  - poetry run python src/pipelines/trainandeval.py
- Infer√™ncia:
  - poetry run python src/modeling/inference.py

---


**Preven√ß√£o de Fraudes em Pix ‚Äî Sistema de detec√ß√£o em tempo real**

**Descri√ß√£o**

Este projeto implementa um pipeline completo para simula√ß√£o de transa√ß√µes, engenharia de atributos, treinamento de modelos (log√≠stica e XGBoost), avalia√ß√£o e infer√™ncia em tempo real. 

A organiza√ß√£o segue pr√°ticas de Data Science, com qualidade garantida por CI, testes e linters.

---


**Tecnologias utilizadas**

- Linguagem: Python 3.12.
- **Ci√™ncia de Dados:**
  - Pandas, Polars, NumPy, PyArrow.
  - Scikit-learn, XGBoost, LightGBM.
  - Matplotlib, Seaborn para visualiza√ß√£o.
- **Qualidade:**
  - Black (formata√ß√£o), Ruff (lint), Isort (imports), Mypy (tipos).
  - Pytest (testes).
- **DevOps:**
  - GitHub Actions (CI), pre-commit, Makefile, Poetry.
 
---


**Requisitos**

- **Hardware:**
  - CPU 4+ cores, 16 GB RAM, SSD recomendado.
- **Software:**
  - Python 3.12, Poetry 1.7+, Git, Make.
  - JupyterLab para notebooks.


---

**Instala√ß√£o e execu√ß√£o**

**1. Clone o reposit√≥rio:**
   - git clone https://github.com/Santosdevbjj/prevencaoFraudesPix.git
   - cd prevencaoFraudesPix
     
**2. Instale depend√™ncias:**
   - poetry install
     
**3. Qualidade:**
   - poetry run black src tests
   - poetry run ruff check src tests --fix
   - poetry run isort src tests
   - poetry run mypy src
     
**4. Pipelines:**
   - poetry run python src/pipelines/build_dataset.py
   - poetry run python src/pipelines/trainandeval.py

**5. Notebooks:**
   - poetry run jupyter lab
   - Abra notebooks/01eda.ipynb, 02featureinspection.ipynb, 03threshold_analysis.ipynb.


--- 

**Estrutura do reposit√≥rio**


<img width="877" height="1270" alt="Screenshot_20251205-192939" src="https://github.com/user-attachments/assets/4c653f2c-4860-4093-88e9-39669e263aae" />
<img width="849" height="1134" alt="Screenshot_20251205-193104" src="https://github.com/user-attachments/assets/59ca820c-f2e4-44c5-bded-c49f4b483868" />



 
---

**Explica√ß√£o das pastas e arquivos**

- **data/**
  - **raw/:** dados brutos simulados ou provenientes de logs.
  - **interim/:** dados intermedi√°rios ap√≥s limpeza/valida√ß√µes.
  - **processed/:** dataset final com features para treino/infer√™ncia.
- **models/**
  - **artifacts/:** modelos treinados, encoders e escalers salvos.
  - **reports/:** relat√≥rios de m√©tricas, curvas ROC/PR, confusion matrices.
- **src/data/**
  - **simulate_transactions.py:** gera transa√ß√µes Pix sint√©ticas com r√≥tulos de fraude, distribui√ß√£o de valores e padr√µes temporais.
  - **schemas.py:** esquemas de colunas (tipos, obrigatoriedade) para garantir consist√™ncia.
  - **utils.py:** utilidades de ingest√£o, valida√ß√£o b√°sica e seed control.
- **src/features/**
  - **timewindowspolars.py:** agrega√ß√µes em janelas de tempo (ex.: contagem por minuto, soma de valores por hora) usando Polars para alta performance.
  - **categorical.py:** encoding/normaliza√ß√£o de vari√°veis categ√≥ricas (ex.: tipo de chave Pix, dispositivo).
  - **validators.py:** guardrails de vazamento e sanidade (ex.: impedir uso de labels futuras).
- **src/modeling/**
  - **train_logreg.py:** pipeline de treinamento com regress√£o log√≠stica, baseline interpret√°vel.
  - **train_xgboost.py:** pipeline avan√ßado com XGBoost, foco em desempenho.
  - **evaluate.py:** avalia√ß√£o com m√©tricas (ROC-AUC, PR-AUC, F1, precis√£o/recall), curvas e relat√≥rios.
  - **inference.py:** fun√ß√£o de predi√ß√£o em tempo real, com carregamento de artefatos e pr√©-processamento id√™ntico ao treino.
- **src/utils/**
  - **io.py:** leitura/escrita de datasets e artefatos com caminhos padronizados.
  - **metrics.py:** m√©tricas customizadas e utilit√°rios de limiar.
  - **config.py:** configura√ß√£o central de caminhos, par√¢metros de treino e janelas.
- **src/pipelines/**
  - **build_dataset.py:** orquestra ingest√£o, valida√ß√µes, engenharia de atributos e persiste dataset final.
  - **trainandeval.py:** treina modelos, salva artefatos e gera relat√≥rios comparativos.
- **tests/**
  - **testtimewindows.py:** testa agrega√ß√µes temporais e consist√™ncia das janelas.
  - **testleakageguards.py:** testa validadores para evitar data leakage.
  - **testinferencelatency.py:** mede lat√™ncia de infer√™ncia e verifica limites.
- **notebooks/**
  - **01_eda.ipynb:** an√°lise explorat√≥ria, distribui√ß√£o de valores, taxas de fraude, sazonalidade.
  - **02featureinspection.ipynb:** import√¢ncia de features, correla√ß√µes, drift potencial.
  - **03thresholdanalysis.ipynb:** an√°lise de trade-off entre precis√£o, recall e custo financeiro.
- **.github/workflows/**
  - **ci.yaml:** pipeline principal de testes e qualidade.
  - **quality.yml:** lint/format/type checks.
  - **auto-fix*.yml:** pipelines opcionais para corre√ß√£o autom√°tica.
- **Configura√ß√£o:**
  - **pyproject.toml:** depend√™ncias, ferramentas de qualidade e configura√ß√£o do projeto.
  - **requirements.txt** e dev-requirements.txt: refer√™ncias alternativas de depend√™ncias.
  - **setup.cfg:** configura√ß√µes de ferramentas (se necess√°rio).
  - **.pre-commit-config.yaml:** hooks de qualidade.
  - **.gitignore:** arquivos ignorados.
  - **Makefile:** comandos padronizados (ex.: build, train, eval).


---

**Como executar**

- **Constru√ß√£o de dataset:**
  - poetry run python src/pipelines/build_dataset.py
- **Treino e avalia√ß√£o:**
  - poetry run python src/pipelines/trainandeval.py
- **Infer√™ncia em tempo real (exemplo):**
  - poetry run python src/modeling/inference.py --input data/processed/realtimebatch.parquet --output models/reports/inferenceoutput.parquet


---

**Exemplos de execu√ß√£o dos notebooks**

- **Inicie Jupyter:**
  - poetry run jupyter lab
- **01_eda.ipynb:**
  - Carregue data/processed/dataset.parquet.
  - Plote distribui√ß√£o de valores por hora; calcule taxa de fraude por janela.
- **02featureinspection.ipynb:**
  - Carregue artefatos do XGBoost.
  - Extraia import√¢ncias e compare com log√≠stica; **visualize SHAP.**
- **03thresholdanalysis.ipynb:**
  - Carregue models/reports/metrics.json.
  - Varie thresholds de 0.1 a 0.9; calcule custo esperado: custofraude √ó falsosnegativos + custooperacional √ó falsospositivos; selecione limiar √≥timo.

---

**Documenta√ß√£o das bibliotecas**

- **pandas, numpy:** manipula√ß√£o e opera√ß√µes num√©ricas.
- **polars:** processamento colunar de alto desempenho, ideal para janelas temporais.
- **pyarrow:** interoperabilidade e parquet/arrow.
- **scikit-learn:** modelos cl√°ssicos, m√©tricas, pipelines.
- **xgboost, lightgbm:** gradient boosting eficientes.
- **joblib:** serializa√ß√£o de artefatos.
- **matplotlib, seaborn:** visualiza√ß√£o.
- **pytest:** testes automatizados.
- **black, ruff, isort, mypy:** qualidade do c√≥digo.



---

**Detalhamento dos arquivos:**

**pyproject.toml**

- Define nome, vers√£o, descri√ß√£o, licen√ßa.
- Lista depend√™ncias de runtime e grupo dev (black, ruff, isort, mypy).
- Configura√ß√µes de Black, Ruff, Isort, Mypy.
- Dica: se n√£o for empacotar, usar package-mode = false ou poetry install --no-root.

**requirements.txt e dev-requirements.txt**

- Alternativas ao Poetry para ambientes onde pip √© preferido.
- requirements.txt: libs de produ√ß√£o (pandas, numpy, scikit-learn, xgboost, lightgbm, polars, pyarrow, matplotlib, seaborn, joblib, pytest).
- dev-requirements.txt: ferramentas de qualidade (black, ruff, isort, mypy).

**Makefile**

- Targets t√≠picos:
  - make setup ‚Üí poetry install, pre-commit install.
  - make data ‚Üí build_dataset.
  - make train ‚Üí trainandeval.
  - make quality ‚Üí black, ruff, isort, mypy.
  - make test ‚Üí pytest.

**src/data**

- simulate_transactions.py:
  - Gera transa√ß√µes com campos: id, timestamp, valor, origem/destino, chave Pix, dispositivo, r√≥tulo fraude.
  - Controla seed, sazonalidade e padr√µes de comportamento suspeito.
- schemas.py:
  - Especifica schema com dtypes (ex.: timestamp como datetime64, valor como float).
  - Fun√ß√µes para validar conformidade do dataset.
- utils.py:
  - Helpers de leitura/escrita e gera√ß√£o de amostras controladas.

**src/features**

- timewindowspolars.py:
  - Fun√ß√µes de agrega√ß√£o por janelas: contagem/valor acumulado por 1min/5min/1h; n√∫mero de destinat√°rios √∫nicos; frequ√™ncia de transa√ß√µes.
  - Implementadas em Polars para performance.
- categorical.py:
  - Encoding de categorias: one-hot/target encoding; normaliza√ß√µes.
- validators.py:
  - Regras anti-vazamento: impede uso de labels futuras; valida separa√ß√£o temporal treino/teste.

**src/modeling**

- train_logreg.py:
  - Pipeline: load dataset, split, scale, treina regress√£o log√≠stica, salva artefatos e m√©tricas.
- train_xgboost.py:
  - Similar ao acima; otimiza hiperpar√¢metros (grid/bayes opcional).
- evaluate.py:
  - Calcula m√©tricas cl√°ssicas; gera relat√≥rios e gr√°ficos, salva em models/reports.
- inference.py:
  - Carrega artefatos, aplica o mesmo pr√©-processamento, prediz risco de fraude; otimiza lat√™ncia.

**src/utils**

- io.py:
  - API de caminho padr√£o; fun√ß√µes de load/save parquet/csv, artefatos joblib.
- metrics.py:
  - M√©tricas customizadas; fun√ß√µes para an√°lise de threshold e custos.
- config.py:
  - Par√¢metros globais (janelas, caminhos de dados, semente, limites de lat√™ncia).

**src/pipelines**

- build_dataset.py:
  - Orquestra simulador ‚Üí valida schema ‚Üí features ‚Üí salva processed.
- trainandeval.py:
  - Treina modelos, compara m√©tricas, salva artefatos e relat√≥rios (gr√°ficos, JSON).

**data/**

- raw/: insumos brutos (simulados).
- interim/: dados p√≥s-valida√ß√µes.
- processed/: dataset final com features e r√≥tulos.

**models/**

- artifacts/: .joblib/.json dos modelos e pr√©-processadores.
- reports/: m√©tricas e gr√°ficos (.png, .json).

**tests/**

- testtimewindows.py: garante janelas corretas e sem inconsist√™ncias.
- testleakageguards.py: verifica aus√™ncia de vazamento.
- testinferencelatency.py: assegura lat√™ncia m√°xima definida e estabilidade.

**notebooks/**

- **01_eda.ipynb:**
  - Explora distribui√ß√£o de transa√ß√µes, sazonalidade, padr√µes de fraude.
- **02featureinspection.ipynb:**
  - Analisa import√¢ncia de features, correla√ß√£o, SHAP opcional.
- **03thresholdanalysis.ipynb:**
  - Seleciona thresholds √≥timos por custo.

**.gitignore**

- Ignora ambientes, caches, dados grandes, artefatos.

**.github/workflows**

- **ci.yaml:**
  - Pytest, qualidade b√°sica e build de artefatos.
- quality.yml:
  - Black (check), Ruff, Isort (check), Mypy.
- auto-fix*.yml:
  - Pipelines auxiliares que aplicam corre√ß√µes autom√°ticas (opcional).

**setup.cfg**

- Centraliza√ß√£o de configs para ferramentas que oferecem integra√ß√£o via setup.cfg (se aplic√°vel).

**.pre-commit-config.yaml**

- Hooks: Black, Ruff (com --fix), Isort.
- Opcional: integra√ß√£o com Mypy e Pytest.

---

**Exemplos:**

**Constru√ß√£o de dataset**

`bash
poetry run python src/pipelines/build_dataset.py \
  --input data/raw/transactions.parquet \
  --output data/processed/dataset.parquet
`

**Treino e avalia√ß√£o**

`bash
poetry run python src/pipelines/trainandeval.py \
  --input data/processed/dataset.parquet \
  --models-out models/artifacts/ \
  --reports-out models/reports/
`

**Infer√™ncia**

`bash
poetry run python src/modeling/inference.py \
  --input data/processed/new_batch.parquet \
  --model models/artifacts/xgb_model.joblib \
  --output models/reports/inference_scores.parquet
`

**Notebooks**

- **01_eda.ipynb:**
  - Carregue dataset: data/processed/dataset.parquet.
  - Crie gr√°ficos: histograma de valores, taxa de fraude por hora/dia.
- **02featureinspection.ipynb:**
  - Import√¢ncias: carregue xgb_model.joblib, plote features por ganho.
- **03thresholdanalysis.ipynb:**
  - Analise m√©tricas por threshold e calcule custo esperado; selecione limiar de decis√£o.

---


‚Äãüß† **Aprendizados e Desafios T√©cnicos**

‚ÄãO desenvolvimento deste sistema trouxe desafios que foram al√©m da modelagem preditiva, exigindo uma mentalidade de Engenharia de Machine Learning (MLOps):

‚Ä¢ **‚ÄãPerformance vs. Lat√™ncia:** O maior desafio t√©cnico foi garantir que o c√°lculo de janelas temporais (contagem de transa√ß√µes no √∫ltimo minuto/hora) fosse perform√°tico.

A substitui√ß√£o do processamento linha a linha por agrega√ß√µes vetorizadas no Polars foi a decis√£o chave para manter a lat√™ncia de infer√™ncia dentro dos limites aceit√°veis para o Pix.

‚Ä¢ **‚ÄãPreven√ß√£o de Data Leakage:** Em dados temporais, √© f√°cil cometer o erro de usar informa√ß√µes do futuro para treinar o modelo. Implementei validadores rigorosos (validators.py) para garantir que as janelas de agrega√ß√£o e o split treino/teste respeitassem estritamente a linha do tempo.

‚Ä¢ **‚ÄãTrade-off Financeiro:** Aprendi que a melhor m√©trica de Machine Learning (como um AUC alto) nem sempre √© a melhor m√©trica de neg√≥cio. 

‚Ä¢ O uso do **Threshold Analysis** me permitiu entender que, em fraudes, o custo de um Falso Negativo (deixar a fraude passar) √© muito superior ao de um Falso Positivo (bloqueio indevido), e calibrei o modelo para minimizar o preju√≠zo financeiro total, n√£o apenas o erro estat√≠stico.

‚Ä¢ **‚ÄãQualidade de Software em Dados:** A implementa√ß√£o de **Type Hinting (Mypy) e Linting (Ruff)** em um pipeline de Data Science foi fundamental para evitar bugs em tempo de execu√ß√£o, demonstrando que c√≥digo de cientista de dados tamb√©m deve ser c√≥digo de produ√ß√£o.




---



## Relat√≥rios executivos


**Relat√≥rio para o CEO**

- **Resumo estrat√©gico:**
  - O sistema reduz perdas por fraude em Pix com decis√£o em tempo real, preservando experi√™ncia do cliente.
- **Benef√≠cios:**
  - Diminui√ß√£o de fraude estimada em X% com incremento Y% em precis√£o, mantendo lat√™ncia m√©dia inferior a 50 ms por transa√ß√£o (meta de produ√ß√£o).
  - Arquitetura replic√°vel e aud√≠tavel, com governan√ßa de dados e qualidade de c√≥digo.
- **Riscos e mitiga√ß√£o:**
  - Drift de dados monitorado com re-treinos peri√≥dicos e alertas.
  - Falsos positivos manejados por thresholds din√¢micos e revis√£o manual em casos de alto impacto.
- **Pr√≥ximos passos:**
  - **Integra√ß√£o com sistemas de risco:** AB testing; amplia√ß√£o de features comportamentais e device intelligence.


---


**Relat√≥rio para o diretor financeiro**

- **Impacto econ√¥mico:**
  - **Modelo de custo:** Custo total = custofraude √ó FN + custooperacional √ó FP.
  - Otimiza√ß√£o de limiar minimiza custo agregado, com simula√ß√µes nos notebooks.
- **Resultados:**
  - ROC-AUC e PR-AUC superiores ao baseline (log√≠stica), XGBoost melhor performance.
  - Cen√°rios por sazonalidade e hor√°rios de pico avaliados.
- **Governan√ßa:**
  - Registros de modelos e relat√≥rios em models/reports; versionamento por commit/tag.
- **Recomenda√ß√£o:**
  - Ado√ß√£o do limiar ùúè que minimiza custo sob restri√ß√µes de SLA e UX; recalibra√ß√£o trimestral.
 

    ---

    

**Relat√≥rio para o gerente financeiro**

- **Opera√ß√£o:**
  - **Processo di√°rio:** ingest√£o ‚Üí features ‚Üí scoring em tempo real ‚Üí revis√£o de alertas.
  - **Monitoramento de KPIs:** taxa de fraude, precis√£o, recall, lat√™ncia, custo por transa√ß√£o.
- **Procedimentos:**
  - **Playbook em incidentes:** fallback para modelo baseline, logging detalhado e revis√£o de regras.
- **Treinamento e ado√ß√£o:**
  - Treinamento de equipe para interpretar relat√≥rios; canal de feedback com time de dados.

---

**Observa√ß√µes finais**

- Este projeto foi desenhado para ser modular, audit√°vel e evolutivo.
- O ecossistema de qualidade (Ruff, Black, Isort, Mypy, Pytest, CI) reduz riscos operacionais e melhora a manutenibilidade.
- Os notebooks complementam a transpar√™ncia anal√≠tica e decis√µes orientadas a custos.

> Reposit√≥rio p√∫blico e estrutura dispon√≠vel no GitHub.



---




**Autor:**
  Sergio Santos 


---

**Contato:**


[![Portf√≥lio S√©rgio Santos](https://img.shields.io/badge/Portf√≥lio-S√©rgio_Santos-111827?style=for-the-badge&logo=githubpages&logoColor=00eaff)](https://santosdevbjj.github.io/portfolio/)
[![LinkedIn S√©rgio Santos](https://img.shields.io/badge/LinkedIn-S√©rgio_Santos-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://linkedin.com/in/santossergioluiz) 

---






